
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#2196f3">
  <script src="../../../_static/javascripts/modernizr.js"></script>
  
  
    <link rel="apple-touch-icon" href="../../../_static/images/apple-icon-152x152.png"/>
  
  
    <title>domid.models.model_vade &#8212; domid  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/material.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  
    <link rel="apple-touch-icon" href="../../../_static/images/apple-icon-152x152.png"/>
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=teal data-md-color-accent=cyan>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#_modules/domid/models/model_vade" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../index.html" title="domid  documentation"
           class="md-header-nav__button md-logo">
          
            <i class="md-icon">school</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">DomId</span>
          <span class="md-header-nav__topic"> domid.models.model_vade </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/agisga/DomId" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    DomId
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../../index.html" class="md-tabs__link">Module code</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../index.html" title="domid documentation" class="md-nav__button md-logo">
      
        <i class="md-icon">school</i>
      
    </a>
    <a href="../../../index.html"
       title="domid documentation">DomId</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/agisga/DomId" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    DomId
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Contents:</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../modules.html" class="md-nav__link">domid</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="">
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <h1 id="modules-domid-models-model-vade--page-root">Source code for domid.models.model_vade</h1><div class="highlight"><pre>
<span></span>import warnings
import numpy as np
import tensorboardX
import torch
import torch.nn as nn
import torch.nn.functional as F
from domainlab.utils.utils_classif import logit2preds_vpic
from tensorboardX import SummaryWriter

from domid.compos.cnn_VAE import ConvolutionalDecoder, ConvolutionalEncoder
from domid.compos.linear_VAE import LinearDecoder, LinearEncoder


<div class="viewcode-block" id="ModelVaDE"><a class="viewcode-back" href="../../../domid.models.html#domid.models.model_vade.ModelVaDE">[docs]</a>class ModelVaDE(nn.Module):
    def __init__(self, zd_dim, d_dim, device, L, i_c, i_h, i_w, args):
        """
        VaDE model (Jiang et al. 2017 "Variational Deep Embedding:
        An Unsupervised and Generative Approach to Clustering") with
        fully connected encoder and decoder.
        :param zd_dim: dimension of the latent space
        :param d_dim: number of clusters for the clustering task
        :param device: device to use, e.g., "cuda" or "cpu"
        :param i_c: number of channels of the input image
        :param i_h: height of the input image
        :param i_w: width of the input image
        :args: command line arguments
        """
        super(ModelVaDE, self).__init__()
        self.zd_dim = zd_dim
        self.d_dim = d_dim
        self.device = device
        self.L = L
        self.args = args
        self.loss_epoch = 0

        self.dim_inject_y = 0

        if self.args.dim_inject_y:
            self.dim_inject_y = self.args.dim_inject_y

        self.dim_inject_domain = 0
        if self.args.path_to_domain:    # FIXME: one can simply read from the file to find out the injected dimension
            self.dim_inject_domain = args.d_dim   # FIXME: allow arbitrary domain vector to be injected


        if self.args.model == "linear":
            self.encoder = LinearEncoder(zd_dim=zd_dim, input_dim=(i_c, i_h, i_w)).to(device)
            self.decoder = LinearDecoder(prior=args.prior, zd_dim=zd_dim, input_dim=(i_c, i_h, i_w)).to(device)
            if self.dim_inject_domain or self.dim_inject_y:
                warnings.warn("linear model decoder does not support label injection")
        else:
            self.encoder = ConvolutionalEncoder(zd_dim=zd_dim, num_channels=i_c, i_w=i_w, i_h=i_h).to(device)
            self.decoder = ConvolutionalDecoder(
                prior=args.prior,
                zd_dim=zd_dim, #50
                domain_dim=self.dim_inject_y, #
                #domain_dim=self.dim_inject_y,
                h_dim=self.encoder.h_dim,
                num_channels=i_c
            ).to(device)
        print(self.encoder)
        print(self.decoder)
        self.log_pi = nn.Parameter(
            torch.FloatTensor(
                self.d_dim,
            )
            .fill_(1.0 / self.d_dim)
            .log(),
            requires_grad=True,
        )
        self.mu_c = nn.Parameter(torch.FloatTensor(self.d_dim, self.zd_dim).fill_(0), requires_grad=True)
        self.log_sigma2_c = nn.Parameter(torch.FloatTensor(self.d_dim, self.zd_dim).fill_(0), requires_grad=True)

        self.loss_writter = tensorboardX.SummaryWriter()

    def _inference(self, x):
        """Auxiliary function for inference
        :param tensor x: Input tensor of a shape [batchsize, 3, horzintal dim, vertical dim].
        :return tensor preds_c: One hot encoded tensor of the predicted cluster assignment (shape: [batch_size, self.d_dim]).
        :return tensor probs_c: Tensor of the predicted cluster probabilities; this is q(c|x) per eq. (16) or gamma_c in eq. (12) (shape: [batch_size, self.d_dim]).
        :return tensor z: Tensor of the latent space representation (shape: [batch_size, self.zd_dim])
        :return tensor z_mu: Tensor of the mean of the latent space representation (shape: [batch_size, self.zd_dim])
        :return tensor z_sigma2_log: Tensor of the log of the variance of the latent space representation (shape: [batch_size, self.zd_dim])
        :return tensor mu_c: Tensor of the estimated cluster means (shape: [self.d_dim, self.zd_dim])
        :return tensor log_sigma2_c: Tensor of the estimated cluster variances (shape: [self.d_dim, self.zd_dim])
        :return tensor pi: Tensor of the estimated cluster prevalences, p(c) (shape: [self.d_dim])
        :return tensor logits: Tensor where each column contains the log-probability p(c)p(z|c) for cluster c=0,...,self.d_dim-1 (shape: [batch_size, self.d_dim]).
        """

        z_mu, z_sigma2_log = self.encoder(x)
        z = torch.randn_like(z_mu) * torch.exp(z_sigma2_log / 2) + z_mu
        pi = F.softmax(self.log_pi, dim=0)
        # if torch.any(pi&lt;0.01):
        #     for i in range(len(pi)):
        #         if pi[i]&lt;0.01:
        #
        #             difference = (0.01-pi[i])/(self.d_dim)
        #             pi+= difference
        #             pi[i]=0.01
                    # pi[:i]+=difference
                    # pi[i+1:]+=difference




        mu_c = self.mu_c
        log_sigma2_c = self.log_sigma2_c

        logits = torch.log(pi.unsqueeze(0)) + self.gaussian_pdfs_log(z, mu_c, log_sigma2_c)
        # shape [batch_size, self.d_dim], each column contains the log-probability p(c)p(z|c) for cluster c=0,...,self.d_dim-1.

        preds_c, probs_c, *_ = logit2preds_vpic(logits)

        return preds_c, probs_c, z, z_mu, z_sigma2_log, mu_c, log_sigma2_c, pi, logits

<div class="viewcode-block" id="ModelVaDE.infer_d_v"><a class="viewcode-back" href="../../../domid.models.html#domid.models.model_vade.ModelVaDE.infer_d_v">[docs]</a>    def infer_d_v(self, x):
        """
        Predict the cluster/domain of the input data.
        Corresponds to equation (16) in the paper.
        :param tensor x: Input tensor of a shape [batchsize, 3, horzintal dim, vertical dim].
        :return tensor preds: One hot encoded tensor of the predicted cluster assignment.
        """
        preds, *_ = self._inference(x)
        return preds.cpu().detach()</div>

<div class="viewcode-block" id="ModelVaDE.infer_d_v_2"><a class="viewcode-back" href="../../../domid.models.html#domid.models.model_vade.ModelVaDE.infer_d_v_2">[docs]</a>    def infer_d_v_2(self, x, inject_domain):
        """
        Used for tensorboard visualizations only.
        """
        results = self._inference(x)
        if len(inject_domain)&gt;0:
            zy = torch.cat((results[2], inject_domain), 1)
        else:
            zy = results[2]


        x_pro, *_ = self.decoder(zy)
        preds, probs, z, z_mu, z_sigma2_log, mu_c, log_sigma2_c, pi, logits = (r.cpu().detach() for r in results)
        return preds, z_mu, z, log_sigma2_c, probs, x_pro</div>

<div class="viewcode-block" id="ModelVaDE.cal_loss"><a class="viewcode-back" href="../../../domid.models.html#domid.models.model_vade.ModelVaDE.cal_loss">[docs]</a>    def cal_loss(self, x, inject_domain, warmup_beta):
        """Function that is called in trainer_vade to calculate loss
        :param x: tensor with input data
        :return: ELBO loss
        """
        return self.ELBO_Loss(x, inject_domain, warmup_beta)</div>

<div class="viewcode-block" id="ModelVaDE.pretrain_loss"><a class="viewcode-back" href="../../../domid.models.html#domid.models.model_vade.ModelVaDE.pretrain_loss">[docs]</a>    def pretrain_loss(self, x, inject_domain):
        Loss = nn.MSELoss()
        #Loss = nn.MSELoss(reduction='sum')
        #Loss = nn.HuberLoss()
        z_mu, z_sigma2_log = self.encoder(x)
        z = torch.randn_like(z_mu) * torch.exp(z_sigma2_log / 2) + z_mu
        if len(inject_domain)&gt;0:
            zy = torch.cat((z, inject_domain), 1)
        else:
            zy = z

        x_pro, *_ = self.decoder(zy)
        loss = Loss(x, x_pro)
        return loss</div>

<div class="viewcode-block" id="ModelVaDE.reconstruction_loss"><a class="viewcode-back" href="../../../domid.models.html#domid.models.model_vade.ModelVaDE.reconstruction_loss">[docs]</a>    def reconstruction_loss(self, x, x_pro, log_sigma):

        if self.args.prior == "Bern":
            L_rec = F.binary_cross_entropy(x_pro, x)
        else:
           #  print('first part',torch.mean(torch.sum(torch.sum(torch.sum(log_sigma, 2), 2), 1), 0))
           # #torch.sum(log_sigma)*1/log_sigma.shape[0])
           #  print('second part',  torch.mean(
           #       torch.sum(torch.sum(torch.sum(0.5 * (x - x_pro) ** 2 / torch.exp(log_sigma) ** 2, 2),2),1), 0))
           #  print('MSE', F.mse_loss(x, x_pro))
           #  print('constant infront of MSE',  torch.sum(torch.exp(log_sigma)**2))
           #  print('x pro min/max/mean', torch.min(x_pro), torch.max(x_pro), torch.mean(x_pro))
           #  print('log_sigma min/max/mean',torch.min(log_sigma), 'max',torch.max(log_sigma), 'mean', torch.mean(log_sigma))

            # L_rec = torch.mean(torch.sum(torch.sum(torch.sum(log_sigma, 2), 2), 1), 0) + torch.mean(
            #     torch.sum(torch.sum(torch.sum(0.5 * (x - x_pro) ** 2 / torch.exp(log_sigma) ** 2, 2), 2), 1), 0
            # )

            sigma = torch.Tensor([0.9]).to(self.device) #mean sigma of all images
            log_sigma_est = torch.log(sigma).to(self.device)
            L_rec = torch.mean(
                torch.sum(torch.sum(torch.sum(0.5 * (x - x_pro) ** 2 , 2), 2), 1), 0
            )/sigma**2
            #L_rec = F.mse_loss(x_pro, x)
            # print(L_rec, L_rec0)


            # print('L rec', L_rec)
            # print("#"*10)
            # L_rec = torch.sum(log_sigma)*1/log_sigma.shape[0]+F.mse_loss(x, x_pro)*(log_sigma.shape[0]/torch.sum(torch.exp(log_sigma)**2))

            #L_rec = F.mse_loss(x, x_pro)#*(log_sigma.shape[0]/torch.sum(torch.exp(log_sigma)**2))

        # Note that the mean is taken over the batch dimension, and the sum over the spatial dimensions and the channels.
        # Thir is consistent with the computation of other terms of the ELBO loss below.


        return L_rec</div>

<div class="viewcode-block" id="ModelVaDE.ELBO_Loss"><a class="viewcode-back" href="../../../domid.models.html#domid.models.model_vade.ModelVaDE.ELBO_Loss">[docs]</a>    def ELBO_Loss(self, x, inject_domain, warmup_beta):
        """ELBO loss function
        Using SGVB estimator and the reparametrization trick calculates ELBO loss.
        Calculates loss between encoded input and input using ELBO equation (12) in the papaer.
        :param tensor x: Input tensor of a shape [batchsize, 3, horzintal dim, vertical dim].
        :param int L: Number of Monte Carlo samples in the SGVB
        """
        preds, probs, z, z_mu, z_sigma2_log, mu_c, log_sigma2_c, pi, logits = self._inference(x)
        # mu, sigma from the decoder
        eps = 1e-10

        L_rec = 0.0
        for l in range(self.L):
            z = torch.randn_like(z_mu) * torch.exp(z_sigma2_log / 2) + z_mu  # shape [batch_size, self.zd_dim]4
            if len(inject_domain)&gt;0:
                zy = torch.cat((z, inject_domain), 1)
            else:
                zy = z

            x_pro, log_sigma = self.decoder(zy)  # x_pro, mu, sigma
            L_rec += self.reconstruction_loss(x, x_pro, log_sigma)


        L_rec /= self.L
        Loss = L_rec * x.size(1)
        # --&gt; this is the -"first line" of eq (12) in the paper with additional averaging over the batch.

        Loss += 0.5 *warmup_beta* torch.mean(
            torch.sum(
                probs
                * torch.sum(
                    log_sigma2_c.unsqueeze(0)
                    + torch.exp(z_sigma2_log.unsqueeze(1) - log_sigma2_c.unsqueeze(0))
                    + (z_mu.unsqueeze(1) - mu_c.unsqueeze(0)).pow(2) / torch.exp(log_sigma2_c.unsqueeze(0)),
                    2,
                ),
                1,
            )
        )
        # inner sum dimentions:
        # [1, d_dim, zd_dim] + exp([batch_size, 1, zd_dim] - [1, d_dim, zd_dim]) + ([batch_size, 1, zd_dim] - [1, d_dim, zd_dim])^2 / exp([1, d_dim, zd_dim])
        # = [batch_size, d_dim, zd_dim] -&gt; sum of zd_dim dimensions
        # the next sum is over d_dim dimensions
        # the mean is over the batch
        # --&gt; overall, this is -"second line of eq. (12)" with additional mean over the batch

        Loss -= warmup_beta*torch.mean(
            torch.sum(probs * torch.log(pi.unsqueeze(0) / (probs + eps)), 1)
        )  # FIXME: (+eps) is a hack to avoid NaN. Is there a better way?
        # dimensions: [batch_size, d_dim] * log([1, d_dim] / [batch_size, d_dim]), where the sum is over d_dim dimensions --&gt; [batch_size] --&gt; mean over the batch --&gt; a scalar

        Loss -= 0.5 * warmup_beta*torch.mean(torch.sum(1.0 + z_sigma2_log, 1))
        # dimensions: mean( sum( [batch_size, zd_dim], 1 ) ) where the sum is over zd_dim dimensions and mean over the batch
        # --&gt; overall, this is -"third line of eq. (12)" with additional mean over the batch


        return Loss</div>

<div class="viewcode-block" id="ModelVaDE.gaussian_pdfs_log"><a class="viewcode-back" href="../../../domid.models.html#domid.models.model_vade.ModelVaDE.gaussian_pdfs_log">[docs]</a>    def gaussian_pdfs_log(self, x, mus, log_sigma2s):
        """helper function"""
        loglik = []
        for c in range(self.d_dim):
            loglik.append(self.gaussian_pdf_log(x, mus[c, :], log_sigma2s[c, :]).view(-1, 1))
        return torch.cat(loglik, 1)</div>

<div class="viewcode-block" id="ModelVaDE.gaussian_pdf_log"><a class="viewcode-back" href="../../../domid.models.html#domid.models.model_vade.ModelVaDE.gaussian_pdf_log">[docs]</a>    @staticmethod
    def gaussian_pdf_log(x, mu, log_sigma2):
        """
        subhelper function just one gausian pdf log calculation, used as a basis for gaussian_pdfs_log function
        :param x: tensor of shape [batch_size, self.zd_dim]
        :param mu: mean for the cluster distribution
        :param log_sigma2: variance parameters of the cluster distribtion
        :return: tensor with the Gaussian log probabilities of the shape of [batch_size, 1]
        """
        return -0.5 * (
            torch.sum(
                np.log(np.pi * 2) + log_sigma2 + (x - mu).pow(2) / torch.exp(log_sigma2),
                1,
            )
        )</div></div>


<div class="viewcode-block" id="test_fun"><a class="viewcode-back" href="../../../domid.models.html#domid.models.model_vade.test_fun">[docs]</a>def test_fun(d_dim, zd_dim, device):
    device = torch.device("cpu")
    model = ModelVaDE(d_dim=d_dim, zd_dim=zd_dim, device=device)
    x = torch.rand(2, 3, 28, 28)
    import numpy as np

    a = np.zeros((2, 10))
    a = np.double(a)
    a[0, 1] = 1.0
    a[1, 8] = 1.0
    a
    y = torch.tensor(a, dtype=torch.float)
    model(x, y)
    model.cal_loss(x)</div>
</pre></div>

          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2022, FDA/CDRH/OSEL/DIDSR..
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>