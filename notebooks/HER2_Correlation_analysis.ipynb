{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fbfac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6cf1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path):\n",
    "    df = pd.read_csv(path+'clustering_results.csv')\n",
    "    \n",
    "    domain = df['predictions'].values\n",
    "    \n",
    "    vec_d = df['vec_d_labels'].values\n",
    "    vec_y = df['vec_y_labels'].values\n",
    "    img_locs = df['image_id_labels'].values\n",
    "\n",
    "    Z = np.load(path + \"Z_space.npy\")\n",
    "\n",
    "    #args = np.loadtxt(path + \"arguments.txt\", dtype=str, usecols=0)  # , delimiter = '\\n')\n",
    "    #img_locs = np.loadtxt(path + \"img_id.txt\", dtype=str)\n",
    "    \n",
    "    return domain, vec_d, vec_y, img_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a97fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_scores_per_experiment(scores, img_locs):\n",
    "    \"\"\"\n",
    "    Parser to get mean scores per image from the cvs file.\n",
    "    The name of the images in the folders are slightly different from the names in the csv file.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    M = []\n",
    "\n",
    "    for prediction in img_locs:\n",
    "        try:\n",
    "            prediction = str(\n",
    "                prediction.split(\"/\")[-1]\n",
    "            )  # depending if the path is full or not, take the img name only\n",
    "        except:\n",
    "            \"not full path\"\n",
    "\n",
    "        if \"s\" in prediction:\n",
    "\n",
    "            N = len(prediction) - 4 - 5\n",
    "            # print(N, prediction[:N])\n",
    "            # print(scores.loc[scores['file name'].str.contains(prediction[:N])])\n",
    "            mean_score = scores.loc[\n",
    "                scores[\"file name\"].str.contains(prediction[:N])\n",
    "            ].mean(axis=1)\n",
    "        if \"S\" in prediction:\n",
    "\n",
    "            N = len(prediction) - 4 - 5\n",
    "            # print(N, prediction[:N])\n",
    "            # print(scores.loc[scores['file name'].str.contains(prediction[:N])])\n",
    "            mean_score = scores.loc[\n",
    "                scores[\"file name\"].str.contains(prediction[:N])\n",
    "            ].mean(axis=1)\n",
    "        else:\n",
    "            N = len(prediction) - 6\n",
    "            # print('secod case', N, prediction[:N])\n",
    "            # print(scores.loc[scores['file name'].str.contains(prediction[:N])])\n",
    "            mean_score = scores.loc[\n",
    "                scores[\"file name\"].str.contains(prediction[:N])\n",
    "            ].mean(axis=1)\n",
    "            # print(mean_score)\n",
    "        mean_score = float(mean_score)\n",
    "        # print(mean_score)\n",
    "        M.append(mean_score)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6011430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please insert yout path to the csv file associated with HER2 data (that contains scores)\n",
    "base_path = \"../../../DomId/HER2\"\n",
    "# base_path = \"/your/data/location\"\n",
    "\n",
    "scores = pd.read_csv(\n",
    "    os.path.join(base_path, \"truthfile_002.csv\"),\n",
    "    names=[\"num\", \"file name\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s_7\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d17b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put path for vade, cdvade, dec in here\n",
    "ex_vade ='2023-04-13 15:54:32.799477/'\n",
    "ex_cdvade ='2023-04-13 15:54:32.799477/'\n",
    "ex_dec ='2023-04-13 15:54:32.799477/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd2cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128256/2250746413.py:23: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean_score = scores.loc[\n",
      "/tmp/ipykernel_128256/2250746413.py:38: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean_score = scores.loc[\n",
      "/tmp/ipykernel_128256/2250746413.py:31: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean_score = scores.loc[\n"
     ]
    }
   ],
   "source": [
    "domain_vade, vec_d_vade, vec_y_vade, img_locs_vade = load_files(ex_vade)\n",
    "M_vade= mean_scores_per_experiment(scores, img_locs_vade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c761c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128256/2250746413.py:23: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean_score = scores.loc[\n",
      "/tmp/ipykernel_128256/2250746413.py:38: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean_score = scores.loc[\n",
      "/tmp/ipykernel_128256/2250746413.py:31: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean_score = scores.loc[\n"
     ]
    }
   ],
   "source": [
    "domain_cdvade,vec_d_cdvade, vec_y_cdvade, img_locs_cdvade = load_files(ex_cdvade)\n",
    "M_cdvade = mean_scores_per_experiment(scores, img_locs_cdvade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644c422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128256/2250746413.py:23: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean_score = scores.loc[\n",
      "/tmp/ipykernel_128256/2250746413.py:38: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean_score = scores.loc[\n",
      "/tmp/ipykernel_128256/2250746413.py:31: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean_score = scores.loc[\n"
     ]
    }
   ],
   "source": [
    "domain_dec, vec_d_dec, vec_y_dec, img_locs_dec = load_files(ex_dec)\n",
    "M_dec = mean_scores_per_experiment(scores, img_locs_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86657988",
   "metadata": {},
   "source": [
    "# Correlation between predicted and true labels ananlysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfc21ef4-128f-4651-9cbd-8ac4eb69a495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct Pearsons CC between predicted domain and mean score -0.08563334425763247\n"
     ]
    }
   ],
   "source": [
    "r = np.corrcoef(domain_vade, M_vade)\n",
    "print('Direct Pearsons CC between predicted domain and mean score', r[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e5fe690-4627-4df3-a1d7-52365122ada2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "def correlation_with_her2_class_label(cluster_pred_scalar, cluster_true_scalar):\n",
    "\n",
    "    cluster_pred_scalar = [item-1 for item in cluster_pred_scalar]\n",
    "    cost = np.zeros((len(np.unique(cluster_pred_scalar)),len(np.unique(cluster_pred_scalar))))\n",
    "    cost = cost - confusion_matrix(cluster_pred_scalar, cluster_true_scalar)\n",
    "\n",
    "    # What is the best permutation?\n",
    "    row_ind, col_ind = linear_sum_assignment(cost)\n",
    "    # Note that row_ind will be equal to [0, 1, ..., cost.shape[0]] because cost is a square matrix.\n",
    "    conf_mat = (-1)*cost[:, col_ind]\n",
    "    # Accuracy for best permutation:\n",
    "    acc_d = np.diag(conf_mat).sum() / conf_mat.sum()\n",
    "    print('Average correlation with the HER2 class labels', acc_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b71ab78-7a45-463d-82d1-b52b7bd9b491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation with the HER2 class labels 0.5014880952380952\n"
     ]
    }
   ],
   "source": [
    "correlation_with_her2_class_label(domain_vade, vec_d_vade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5428368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation with the HER2 class labels 0.5014880952380952\n"
     ]
    }
   ],
   "source": [
    "correlation_with_her2_class_label(domain_cdvade, vec_d_cdvade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a37f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation with the HER2 class labels 0.5014880952380952\n"
     ]
    }
   ],
   "source": [
    "correlation_with_her2_class_label(domain_dec, vec_d_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba07bc",
   "metadata": {},
   "source": [
    "# Per Predicted domain analysis (not used in miccai submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b93adc-c6c7-4f7e-bbb7-e8ba1fef7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hungarian algorithm to for the predicted domain/HER2 class correlation \n",
    "def domain_class_mapping(domain):\n",
    "    dic1 = {1: 1, 2: 2, 3: 3}\n",
    "    dic2 = {1: 1, 2: 3, 3: 2}\n",
    "    dic3 = {1: 2, 2: 1, 3: 3}\n",
    "    dic4 = {1: 2, 2: 3, 3: 1}\n",
    "    dic5 = {1: 3, 2: 2, 3: 1}\n",
    "    dic6 = {1: 3, 2: 1, 3: 2}\n",
    "    dictionaries = [dic1, dic2, dic3, dic4, dic5, dic6]\n",
    "    combos = []\n",
    "    for i in range(0, 6):\n",
    "        mapping = dictionaries[i]\n",
    "        new_combination =[]\n",
    "        for j in domain:\n",
    "            new_combination.append(mapping[j])\n",
    "        combos.append(new_combination)\n",
    "            \n",
    "        \n",
    "    return combos, dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c337ad-58c2-4d34-965d-87e24ee18d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3253ccc-8e19-473c-a76f-6fb424cfa6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted domain 1 has the highest correlation of 0.3845243471414209 with scores of HER2 class  2\n",
      "The following Hungarian mapping was used: {1: 2, 2: 3, 3: 1}\n"
     ]
    }
   ],
   "source": [
    "combos_vade, dictionaries = domain_class_mapping(domain_vade)\n",
    "R_values_vade = []\n",
    "for i in combos_vade:\n",
    "    r =  np.corrcoef(i, M_vade)\n",
    "    R_values_vade.append(r[0][1])\n",
    "\n",
    "print('Predicted domain 1 has the highest correlation of', max(R_values_vade), 'with scores of HER2 class ', dictionaries[np.argmax(R_values_vade)][1])\n",
    "print('The following Hungarian mapping was used:',dictionaries[np.argmax(R_values_vade)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d7a21a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted domain 2 has the highest correlation of 0.3845243471414209 with scores of HER2 class  3\n",
      "The following Hungarian mapping was used: {1: 2, 2: 3, 3: 1}\n"
     ]
    }
   ],
   "source": [
    "combos_cdvade, dictionaries = domain_class_mapping(domain_cdvade)\n",
    "R_values_cdvade = []\n",
    "for i in combos_cdvade:\n",
    "    r =  np.corrcoef(i, M_cdvade)\n",
    "    R_values_cdvade.append(r[0][1])\n",
    "\n",
    "print('Predicted domain 2 has the highest correlation of', max(R_values_cdvade), 'with scores of HER2 class ', dictionaries[np.argmax(R_values_cdvade)][2])\n",
    "print('The following Hungarian mapping was used:',dictionaries[np.argmax(R_values_cdvade)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04619e01-4781-4d7b-a583-643445c6c71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted domain 2 has the highest correlation of 0.3845243471414209 with scores of HER2 class  3\n",
      "The following Hungarian mapping was used: {1: 2, 2: 3, 3: 1}\n"
     ]
    }
   ],
   "source": [
    "combos_dec, dictionaries = domain_class_mapping(domain_dec)\n",
    "R_values_dec = []\n",
    "for i in combos_dec:\n",
    "    r =  np.corrcoef(i, M_dec)\n",
    "    R_values_dec.append(r[0][1])\n",
    "\n",
    "print('Predicted domain 2 has the highest correlation of', max(R_values_dec), 'with scores of HER2 class ', dictionaries[np.argmax(R_values_dec)][2])\n",
    "print('The following Hungarian mapping was used:',dictionaries[np.argmax(R_values_dec)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a3ec9-4fd5-4011-85a2-275623d3d001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
